{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/diegomrodrigues/my_gpt/blob/main/GT2%20Starter%20Implementation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tiktoken datasets --quiet"
      ],
      "metadata": {
        "id": "0oGMHiz0Yc3y",
        "outputId": "c4b982a4-e63d-4c1f-fb1a-79e903fbdfc7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m46.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/527.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m527.3/527.3 kB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.9/39.9 MB\u001b[0m \u001b[31m50.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 17.0.0 which is incompatible.\n",
            "ibis-framework 8.0.0 requires pyarrow<16,>=2, but you have pyarrow 17.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import math\n",
        "from torch import nn\n",
        "\n",
        "def gelu(x):\n",
        "    return 0.5 * x * (1 + torch.tanh(math.sqrt(2 / math.pi) * (x + 0.044715 * torch.pow(x, 3))))"
      ],
      "metadata": {
        "id": "zO3DhFuK3gQC"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LayerNorm(nn.Module):\n",
        "    def __init__(self, hidden_size, eps=1e-12):\n",
        "        super(LayerNorm, self).__init__()\n",
        "\n",
        "        # Parâmetros aprendíveis para escala (gamma) e deslocamento (beta)\n",
        "        # Inicializados com 1s e 0s respectivamente\n",
        "        self.weight = nn.Parameter(torch.ones(hidden_size))\n",
        "        self.bias = nn.Parameter(torch.zeros(hidden_size))\n",
        "\n",
        "        # Epsilon para estabilidade numérica\n",
        "        self.epsilon = eps\n",
        "\n",
        "    def forward(self, x):  # x: [batch_size, seq_length, hidden_size]\n",
        "        # Calcula a média ao longo da última dimensão (feature dimension)\n",
        "        # keepdim=True mantém a dimensionalidade para broadcast correto\n",
        "        mu = x.mean(-1, keepdim=True)  # [batch_size, seq_length, 1]\n",
        "\n",
        "        # Calcula a variância\n",
        "        # Usa a fórmula E[(X - μ)^2] para variância\n",
        "        sigma = (x - mu).pow(2).mean(-1, keepdim=True)  # [batch_size, seq_length, 1]\n",
        "\n",
        "        # Normalização: (x - μ) / sqrt(σ^2 + ε)\n",
        "        # Epsilon (ε) evita divisão por zero\n",
        "        x = (x - mu) / torch.sqrt(sigma + self.epsilon)  # [batch_size, seq_length, hidden_size]\n",
        "\n",
        "        # Aplica transformação afim com parâmetros aprendíveis\n",
        "        # y = γ * x + β, onde γ = self.weight e β = self.bias\n",
        "        return self.weight * x + self.bias  # [batch_size, seq_length, hidden_size]\n"
      ],
      "metadata": {
        "id": "UQi_rebQ3yYr"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Conv1D(nn.Module):\n",
        "    def __init__(self, nf, nx):\n",
        "        # nf: número de filtros (saída)\n",
        "        # nx: tamanho da entrada\n",
        "        super(Conv1D, self).__init__()\n",
        "\n",
        "        self.nf = nf\n",
        "\n",
        "        # Inicializa os pesos com uma distribuição normal\n",
        "        # [nx, nf]\n",
        "        w = torch.empty(nx, nf)\n",
        "        nn.init.normal_(w, std=0.02)\n",
        "\n",
        "        # Cria parâmetros treináveis para pesos e vieses\n",
        "        self.weight = nn.Parameter(w)  # [nx, nf]\n",
        "        self.bias = nn.Parameter(torch.zeros(nf))  # [nf]\n",
        "\n",
        "    def forward(self, x): # x: [batch_size, input_len, nx]\n",
        "\n",
        "        # Prepara o shape de saída\n",
        "        size_out = x.size()[:-1] + (self.nf,) # [batch_size, input_len, nf]\n",
        "\n",
        "        # Reshape x para 2D\n",
        "        x_2d = x.view(-1, x.size(-1)) # [batch_size * input_len, nx]\n",
        "\n",
        "        # Aplica a transformação linear\n",
        "        # torch.addmm realiza: out = beta * self.bias + alpha * (x_2d @ self.weight)\n",
        "        x_transformed = torch.addmm(self.bias, x_2d, self.weight) # [batch_size * input_len, nf]\n",
        "\n",
        "        # Reshape de volta para 3D\n",
        "        x_output = x_transformed.view(*size_out) # [batch_size, input_len, nf]\n",
        "\n",
        "        return x_output"
      ],
      "metadata": {
        "id": "SgKl1baE5tCX"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SingleHeadAttention(nn.Module):\n",
        "    def __init__(self, nx, n_ctx, scale=False):\n",
        "        super(SingleHeadAttention, self).__init__()\n",
        "\n",
        "        # nx: dimensão do modelo (tamanho dos embeddings)\n",
        "        self.nx = nx\n",
        "        # n_ctx: comprimento máximo do contexto (número máximo de tokens na sequência)\n",
        "        self.n_ctx = n_ctx\n",
        "\n",
        "        # Performar scaled dot product?\n",
        "        self.scale = scale\n",
        "\n",
        "        # Criamos uma máscara de atenção triangular inferior (causal)\n",
        "        # Isso garante que cada token só preste atenção aos tokens anteriores\n",
        "        # Shape: [1, 1, n_ctx, n_ctx]\n",
        "        self.register_buffer(\"bias\", torch.tril(torch.ones(n_ctx, n_ctx)).view(1, 1, n_ctx, n_ctx))\n",
        "\n",
        "        # Camada linear para projetar a entrada em Query, Key, Value\n",
        "        # Multiplica por 3 porque criamos Q, K, V de uma vez\n",
        "        self.c_attn = Conv1D(nx * 3, nx)\n",
        "        # Camada linear para projetar a saída da atenção de volta ao espaço do modelo\n",
        "        self.c_proj = Conv1D(nx, nx)\n",
        "\n",
        "    def _attention(self, q, k, v):\n",
        "        # Calculamos os scores de atenção: Query * Key^T\n",
        "        # Isso mede quanto cada token (Query) deve prestar atenção a cada outro token (Key)\n",
        "        w = torch.matmul(q, k)  # [batch_size, 1, n_ctx, n_ctx]\n",
        "\n",
        "        # Aplicamos escala opcional para estabilizar o treinamento\n",
        "        # Dividimos pelo sqrt da dimensão para evitar que os gradientes fiquem muito grandes\n",
        "        if self.scale:\n",
        "            w = w / math.sqrt(v.size(-1))\n",
        "\n",
        "        # Preparamos a máscara causal\n",
        "        # Isso garante que não olhamos para tokens futuros\n",
        "        nd, ns = w.size(-2), w.size(-1)\n",
        "        mask = self.bias[:,:,ns-nd:ns,:ns]\n",
        "\n",
        "        # Aplicamos a máscara causal\n",
        "        # Colocamos -infinito onde a máscara é 0, efetivamente zerando esses scores no softmax\n",
        "        w = w * mask - 1e10 * (1 - mask)\n",
        "\n",
        "        # Aplicamos softmax para obter os pesos de atenção\n",
        "        # Isso normaliza os scores para que somem 1 para cada query\n",
        "        w = nn.Softmax(dim=-1)(w)\n",
        "\n",
        "        # Calculamos a saída da atenção: pesos de atenção * Values\n",
        "        # Isso agrega as informações dos tokens relevantes\n",
        "        output = torch.matmul(w, v)  # [batch_size, 1, n_ctx, nx]\n",
        "\n",
        "        return output\n",
        "\n",
        "    def forward(self, x, layer_past=None):\n",
        "        # x: entrada [batch_size, n_ctx, nx]\n",
        "\n",
        "        # Projetamos a entrada para Query, Key, Value de uma vez\n",
        "        qkv = self.c_attn(x)  # [batch_size, n_ctx, nx*3]\n",
        "\n",
        "        # Separamos Q, K, V\n",
        "        query, key, value = qkv.split(self.nx, dim=2)  # cada um: [batch_size, n_ctx, nx]\n",
        "\n",
        "        # Reshape para adicionar dimensão de cabeça (neste caso, apenas 1)\n",
        "        # Isso prepara os tensores para a operação de atenção\n",
        "        query = query.unsqueeze(1)  # [batch_size, 1, n_ctx, nx]\n",
        "        key = key.unsqueeze(1).transpose(-1, -2)  # [batch_size, 1, nx, n_ctx]\n",
        "        value = value.unsqueeze(1)  # [batch_size, 1, n_ctx, nx]\n",
        "\n",
        "        # Lidamos com o cache do estado passado, se fornecido\n",
        "        # Isso é útil para geração incremental de texto\n",
        "        if layer_past:\n",
        "            past_key, past_value = layer_past\n",
        "            key = torch.cat((past_key, key), dim=-1)\n",
        "            value = torch.cat((past_value, value), dim=-2)\n",
        "\n",
        "        # Armazenamos o estado atual para uso futuro\n",
        "        present = torch.stack((key.transpose(-1, -2), value))\n",
        "\n",
        "        # Calculamos a atenção\n",
        "        attn_output = self._attention(query, key, value)  # [batch_size, 1, n_ctx, nx]\n",
        "\n",
        "        # Removemos a dimensão da cabeça (que era 1)\n",
        "        attn_output = attn_output.squeeze(1)  # [batch_size, n_ctx, nx]\n",
        "        # Aplicamos a projeção final para voltar ao espaço do modelo\n",
        "        attn_output = self.c_proj(attn_output)  # [batch_size, n_ctx, nx]\n",
        "\n",
        "        return attn_output, present"
      ],
      "metadata": {
        "id": "YOq_jfcM7njk"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, nx, n_ctx, n_head, scale=False):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "\n",
        "        # Cria uma máscara de atenção triangular inferior (causal)\n",
        "        # Isso garante que cada token só preste atenção aos tokens anteriores\n",
        "        # Shape: [1, 1, n_ctx, n_ctx]\n",
        "        self.register_buffer(\"bias\", torch.tril(torch.ones(n_ctx, n_ctx)).view(1, 1, n_ctx, n_ctx))\n",
        "\n",
        "        self.n_head = n_head  # Número de cabeças de atenção\n",
        "        self.split_size = nx  # Tamanho da dimensão do modelo\n",
        "        self.scale = scale    # Flag para aplicar escala nos scores de atenção\n",
        "\n",
        "        # Camada linear para projetar a entrada em Query, Key, Value para todas as cabeças\n",
        "        self.c_attn = Conv1D(nx * 3, nx)\n",
        "        # Camada linear para projetar a saída da atenção de volta ao espaço do modelo\n",
        "        self.c_proj = Conv1D(nx, nx)\n",
        "\n",
        "    def _attention(self, q, k, v):\n",
        "        # Calcula os scores de atenção: Query * Key^T\n",
        "        # Shape: [batch_size, n_head, seq_len, seq_len]\n",
        "        w = torch.matmul(q, k)\n",
        "\n",
        "        # Aplica escala opcional para estabilizar o treinamento\n",
        "        if self.scale:\n",
        "            w = w / math.sqrt(v.size(-1))\n",
        "\n",
        "        # Prepara e aplica a máscara causal\n",
        "        nd, ns = w.size(-2), w.size(-1)\n",
        "        mask = self.bias[:, :, ns-nd:ns, :ns]\n",
        "        w = w * mask - 1e10 * (1 - mask)  # Aplica -inf onde a máscara é 0\n",
        "\n",
        "        # Aplica softmax para obter os pesos de atenção\n",
        "        w = nn.Softmax(dim=-1)(w)\n",
        "\n",
        "        # Calcula a saída da atenção: pesos de atenção * Values\n",
        "        output = torch.matmul(w, v)\n",
        "        return output\n",
        "\n",
        "    def _merge_heads(self, x):\n",
        "        # Reorganiza o tensor de [batch, head, seq, features] para [batch, seq, head*features]\n",
        "        x = x.permute(0, 2, 1, 3).contiguous()\n",
        "        new_x_shape = x.size()[:-2] + (x.size(-2) * x.size(-1),)\n",
        "        return x.view(*new_x_shape)\n",
        "\n",
        "    def _split_heads(self, x, k=False):\n",
        "        # Divide o último dimensão em [n_head, features/n_head]\n",
        "        new_x_shape = x.size()[:-1] + (self.n_head, x.size(-1) // self.n_head)\n",
        "        x = x.view(*new_x_shape)\n",
        "\n",
        "        # Reorganiza o tensor para [batch, head, seq, features/n_head]\n",
        "        if k:\n",
        "            # Para as keys, colocamos a dim seq por último para otimizar a multiplicação de matrizes\n",
        "            return x.permute(0, 2, 3, 1)\n",
        "        else:\n",
        "            return x.permute(0, 2, 1, 3)\n",
        "\n",
        "    def forward(self, x, layer_past=None):\n",
        "        # x: entrada [batch_size, seq_len, nx]\n",
        "\n",
        "        # Projeta a entrada para Q, K, V de uma vez\n",
        "        qkv = self.c_attn(x)  # [batch_size, seq_len, nx*3]\n",
        "\n",
        "        # Separa Q, K, V\n",
        "        query, key, value = qkv.split(self.split_size, dim=2)\n",
        "        # query, key, value: cada um [batch_size, seq_len, nx]\n",
        "\n",
        "        # Divide as cabeças e reorganiza\n",
        "        query = self._split_heads(query)  # [batch_size, n_head, seq_len, nx/n_head]\n",
        "        key = self._split_heads(key, k=True)  # [batch_size, n_head, nx/n_head, seq_len]\n",
        "        value = self._split_heads(value)  # [batch_size, n_head, seq_len, nx/n_head]\n",
        "\n",
        "        # Lida com o cache do estado passado, se fornecido\n",
        "        if layer_past:\n",
        "            past_key, past_value = layer_past[0].transpose(-2, -1), layer_past[1]\n",
        "            key = torch.cat((past_key, key), dim=-1)  # [batch_size, n_head, nx/n_head, seq_len_extended]\n",
        "            value = torch.cat((past_value, value), dim=-2)  # [batch_size, n_head, seq_len_extended, nx/n_head]\n",
        "\n",
        "        # Armazena o estado atual para uso futuro\n",
        "        present = torch.stack((key.transpose(-2, -1), value))\n",
        "        # present: [2, batch_size, n_head, seq_len, nx/n_head]\n",
        "\n",
        "        # Calcula a atenção para todas as cabeças\n",
        "        attn_output = self._attention(query, key, value)\n",
        "        # [batch_size, n_head, seq_len, nx/n_head]\n",
        "\n",
        "        # Combina as cabeças novamente\n",
        "        attn_output = self._merge_heads(attn_output)  # [batch_size, seq_len, nx]\n",
        "\n",
        "        # Projeta de volta para o espaço do modelo\n",
        "        attn_output = self.c_proj(attn_output)  # [batch_size, seq_len, nx]\n",
        "\n",
        "        return attn_output, present"
      ],
      "metadata": {
        "id": "alztff99Kwmp"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self, n_state, n_embed):\n",
        "        super(MLP, self).__init__()\n",
        "\n",
        "        # n_state: geralmente 4 * n_embed, seguindo a arquitetura original do Transformer\n",
        "        # n_embed: dimensão do modelo (embedding dimension)\n",
        "\n",
        "        # Primeira camada linear: expande a dimensão\n",
        "        self.c_fc = Conv1D(n_state, n_embed)\n",
        "\n",
        "        # Segunda camada linear: projeta de volta para a dimensão original\n",
        "        self.c_proj = Conv1D(n_embed, n_state)\n",
        "\n",
        "        # Função de ativação GELU (Gaussian Error Linear Unit)\n",
        "        self.activation = gelu\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: entrada [batch_size, seq_len, n_embed]\n",
        "\n",
        "        # Aplica a primeira transformação linear e a função de ativação\n",
        "        h = self.c_fc(x)  # [batch_size, seq_len, n_state]\n",
        "        h = self.activation(h)  # [batch_size, seq_len, n_state]\n",
        "\n",
        "        # Aplica a segunda transformação linear\n",
        "        h2 = self.c_proj(h)  # [batch_size, seq_len, n_embed]\n",
        "\n",
        "        return h2  # [batch_size, seq_len, n_embed]"
      ],
      "metadata": {
        "id": "S56U3zCxN3HB"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, n_ctx, config, scale=False):\n",
        "        super(TransformerBlock, self).__init__()\n",
        "\n",
        "        nx     = config.n_embed  # Dimensão do modelo\n",
        "        n_head = config.n_head   # Número de heads\n",
        "\n",
        "        # Primeira camada de normalização, aplicada antes da atenção\n",
        "        self.ln_1 = LayerNorm(nx, eps=config.layer_norm_epsilon)\n",
        "\n",
        "        # Camada de atenção (neste caso, atenção de cabeça única)\n",
        "        if n_head <= 1:\n",
        "            self.attention = SingleHeadAttention(nx, n_ctx, scale)\n",
        "        else:\n",
        "            self.attention = MultiHeadAttention(nx, n_ctx, n_head, scale)\n",
        "\n",
        "        # Segunda camada de normalização, aplicada antes da MLP\n",
        "        self.ln_2 = LayerNorm(nx, eps=config.layer_norm_epsilon)\n",
        "\n",
        "        # MLP (Feed-Forward Network)\n",
        "        self.mlp = MLP(4 * nx, nx)\n",
        "\n",
        "    def forward(self, x, layer_past=None):\n",
        "        # x: entrada [batch_size, seq_len, nx]\n",
        "\n",
        "        # Primeira normalização de camada\n",
        "        normalized_x = self.ln_1(x)  # [batch_size, seq_len, nx]\n",
        "\n",
        "        # Camada de atenção\n",
        "        attention_output, present = self.attention(normalized_x, layer_past=layer_past)\n",
        "        # attention_output: [batch_size, seq_len, nx]\n",
        "        # present: estado cacheado para geração incremental\n",
        "\n",
        "        # Conexão residual após a atenção\n",
        "        x = x + attention_output  # [batch_size, seq_len, nx]\n",
        "\n",
        "        # Segunda normalização de camada\n",
        "        normalized_x = self.ln_2(x)  # [batch_size, seq_len, nx]\n",
        "\n",
        "        # MLP\n",
        "        mlp_output = self.mlp(normalized_x)  # [batch_size, seq_len, nx]\n",
        "\n",
        "        # Conexão residual após a MLP\n",
        "        x = x + mlp_output  # [batch_size, seq_len, nx]\n",
        "\n",
        "        return x, present"
      ],
      "metadata": {
        "id": "XmPj9ydMOgL2"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class Transformer(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "\n",
        "        self.n_layer = config.n_layer  # Número de camadas do Transformer\n",
        "        self.n_embed = config.n_embed  # Dimensão do embedding\n",
        "        self.n_vocab = config.n_vocab  # Tamanho do vocabulário\n",
        "        self.n_pos   = config.n_pos    # Número máximo de posições\n",
        "\n",
        "        # Embedding de tokens\n",
        "        self.wte = nn.Embedding(self.n_vocab, self.n_embed)\n",
        "        # Embedding de posições\n",
        "        self.wpe = nn.Embedding(self.n_pos, self.n_embed)\n",
        "\n",
        "        # Cria um bloco do Transformer\n",
        "        block = TransformerBlock(config.n_ctx, config, scale=True)\n",
        "\n",
        "        # Cria uma lista de blocos do Transformer\n",
        "        self.h = nn.ModuleList([copy.deepcopy(block) for _ in range(self.n_layer)])\n",
        "\n",
        "        # Camada final de normalização\n",
        "        self.ln_f = LayerNorm(self.n_embed, eps=config.layer_norm_epsilon)\n",
        "\n",
        "    def forward(self, input_ids, position_ids=None, token_type_ids=None, past=None):\n",
        "        # input_ids: [batch_size, seq_len]\n",
        "\n",
        "        if past is None:\n",
        "            past_length = 0\n",
        "            past = [None] * len(self.h)\n",
        "        else:\n",
        "            past_length = past[0][0].size(-2)\n",
        "\n",
        "        if position_ids is None:\n",
        "            # Gera ids de posição se não fornecidos\n",
        "            position_ids = torch.arange(past_length, input_ids.size(-1) + past_length, dtype=torch.long, device=input_ids.device)\n",
        "            position_ids = position_ids.unsqueeze(0).expand_as(input_ids)  # [batch_size, seq_len]\n",
        "\n",
        "        input_shape = input_ids.size()\n",
        "        input_ids = input_ids.view(-1, input_ids.size(-1))  # [batch_size * seq_len]\n",
        "        position_ids = position_ids.view(-1, position_ids.size(-1))  # [batch_size * seq_len]\n",
        "\n",
        "        # Aplica embeddings de tokens e posições\n",
        "        input_embeds = self.wte(input_ids)  # [batch_size * seq_len, n_embed]\n",
        "        position_embeds = self.wpe(position_ids)  # [batch_size * seq_len, n_embed]\n",
        "\n",
        "        if token_type_ids is not None:\n",
        "            token_type_ids = token_type_ids.view(-1, token_type_ids.size(-1))\n",
        "            token_type_embeds = self.wte(token_type_ids)  # [batch_size * seq_len, n_embed]\n",
        "        else:\n",
        "            token_type_embeds = 0\n",
        "\n",
        "        # Soma todos os embeddings\n",
        "        hidden_states = input_embeds + position_embeds + token_type_embeds  # [batch_size * seq_len, n_embed]\n",
        "\n",
        "        presents = []\n",
        "        for block, layer_past in zip(self.h, past):\n",
        "            hidden_states, present = block(hidden_states, layer_past)\n",
        "            # hidden_states: [batch_size * seq_len, n_embed]\n",
        "            presents.append(present)\n",
        "\n",
        "        # Aplica a normalização final\n",
        "        hidden_states = self.ln_f(hidden_states)  # [batch_size * seq_len, n_embed]\n",
        "\n",
        "        # Reshape para a forma original\n",
        "        output_shape = input_shape + (hidden_states.size(-1),)\n",
        "        hidden_states = hidden_states.view(*output_shape)  # [batch_size, seq_len, n_embed]\n",
        "\n",
        "        return hidden_states, presents"
      ],
      "metadata": {
        "id": "a8HrzC9JO-zG"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class LinearReadoutHead(nn.Module):\n",
        "    \"\"\"\n",
        "    Cabeça de leitura linear para o modelo GPT.\n",
        "    Esta classe é responsável por projetar os estados ocultos de volta para o espaço do vocabulário.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, model_embedding_weights: nn.Parameter, config: 'GPTConfig'):\n",
        "        super().__init__()\n",
        "        # Dimensão dos embeddings\n",
        "        self.n_embed = config.n_embed\n",
        "        # Tamanho do vocabulário\n",
        "        self.n_vocab = config.n_vocab\n",
        "        self.set_embedding_weights(model_embedding_weights)\n",
        "\n",
        "    def set_embedding_weights(self, model_embedding_weights: nn.Parameter):\n",
        "        # Cria a camada linear do decodificador sem viés\n",
        "        self.decoder = nn.Linear(self.n_embed, self.n_vocab, bias=False)\n",
        "\n",
        "        # Define os pesos do decodificador como os pesos de embedding\n",
        "        self.decoder.weight = model_embedding_weights\n",
        "\n",
        "    def forward(self, hidden_state: torch.Tensor) -> torch.Tensor:\n",
        "        lm_logits = self.decoder(hidden_state)\n",
        "        return lm_logits"
      ],
      "metadata": {
        "id": "UsaMVOjvrbAG"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from dataclasses import dataclass, field\n",
        "\n",
        "@dataclass\n",
        "class GPTConfig:\n",
        "    # Tamanho do vocabulário\n",
        "    n_vocab: int = 50257\n",
        "    # Tamanho do position embedding\n",
        "    n_pos: int = 1024\n",
        "    # Tamanho da janela de contexto (comprimento máximo da sequência)\n",
        "    n_ctx: int = 1024\n",
        "    # Dimensão dos embeddings\n",
        "    n_embed: int = 768\n",
        "    # Número de camadas do transformer\n",
        "    n_layer: int = 12\n",
        "    # Número de cabeças de atenção\n",
        "    n_head: int = 12\n",
        "    # Dimensão interna da camada feed-forward\n",
        "    n_inner: int = field(init=False)\n",
        "    # Epsilon para normalização de camada\n",
        "    layer_norm_epsilon: float = 1e-5\n",
        "    # Intervalo para inicialização de pesos\n",
        "    initializer_range: float = 0.02\n",
        "    # Se deve usar atenção de produto escalar escalado\n",
        "    use_scaled_attention: bool = True\n",
        "\n",
        "    batch_size: int = 32\n",
        "    learning_rate: float = 1e-4\n",
        "    num_epochs: int = 10"
      ],
      "metadata": {
        "id": "MeCkqaE8TM1w"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GPT2(nn.Module):\n",
        "\n",
        "    def __init__(self, config: 'GPTConfig'):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.transformer = Transformer(config)\n",
        "        self.readout_head = LinearReadoutHead(self.transformer.wte.weight, config)\n",
        "\n",
        "    def set_tied(self):\n",
        "        \"\"\"\n",
        "        Vincula os pesos da camada de embedding com a cabeça de leitura linear.\n",
        "        Isso implementa o compartilhamento de pesos entre a entrada e a saída do modelo.\n",
        "        \"\"\"\n",
        "        self.readout_head.set_embedding_weights(self.transformer.wte.weight)\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        input_ids: torch.LongTensor,\n",
        "        position_ids: torch.LongTensor = None,\n",
        "        token_type_ids: torch.LongTensor = None,\n",
        "        past: torch.Tensor = None\n",
        "    ) -> tuple[torch.Tensor, torch.Tensor]:\n",
        "        \"\"\"\n",
        "        Realiza a passagem para frente do modelo GPT-2.\n",
        "\n",
        "        :param input_ids: IDs dos tokens de entrada\n",
        "        :param position_ids: IDs das posições (opcional)\n",
        "        :param token_type_ids: IDs dos tipos de token (opcional)\n",
        "        :param past: Estado passado para geração incremental (opcional)\n",
        "        :return: Uma tupla contendo os logits de saída e os estados presentes\n",
        "        \"\"\"\n",
        "        # Passa a entrada pelo transformer\n",
        "        hidden_states, presents = self.transformer(input_ids, position_ids, token_type_ids, past)\n",
        "\n",
        "        # Passa os estados ocultos pela cabeça de leitura linear\n",
        "        logits = self.readout_head(hidden_states)\n",
        "\n",
        "        return logits, presents"
      ],
      "metadata": {
        "id": "oMXoKzShrFgd"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from datasets import load_dataset\n",
        "import tiktoken\n",
        "from tqdm import tqdm\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from huggingface_hub import notebook_login\n"
      ],
      "metadata": {
        "id": "fS5GJYl_YSYk"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def train_gpt(model, train_data, val_data, config):\n",
        "    if torch.cuda.is_available():\n",
        "        device = torch.device(\"cuda\")\n",
        "    else:\n",
        "        device = torch.device(\"cpu\")\n",
        "\n",
        "    print(f\"Setting device to {device}\")\n",
        "\n",
        "    model.to(device)\n",
        "\n",
        "    train_dataset = TensorDataset(train_data)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=config.learning_rate)\n",
        "\n",
        "    # Set up TensorBoard\n",
        "    writer = SummaryWriter()\n",
        "\n",
        "    for epoch in range(config.num_epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "\n",
        "        for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{config.num_epochs}\"):\n",
        "            inputs = batch[0].to(device)\n",
        "            targets = inputs[:, 1:].contiguous()\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            logits, _ = model(inputs[:, :-1])\n",
        "\n",
        "            logits = logits.view(-1, logits.size(-1))\n",
        "            targets = targets.view(-1)\n",
        "\n",
        "            loss = criterion(logits, targets)\n",
        "\n",
        "            loss.backward()\n",
        "\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        avg_train_loss = total_loss / len(train_loader)\n",
        "        writer.add_scalar(\"Loss/train\", avg_train_loss, epoch)\n",
        "\n",
        "        model.eval()\n",
        "        val_loss = evaluate(model, val_data, criterion, device)\n",
        "        writer.add_scalar(\"Loss/validation\", val_loss, epoch)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{config.num_epochs}, \"\n",
        "              f\"Train Loss: {avg_train_loss:.4f}, \"\n",
        "              f\"Val Loss: {val_loss:.4f}\")\n",
        "\n",
        "    writer.close()\n",
        "\n",
        "def evaluate(model, val_data, criterion, device):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "\n",
        "    val_dataset = TensorDataset(val_data)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=config.batch_size)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in val_loader:\n",
        "            inputs = batch[0].to(device)\n",
        "            targets = inputs[:, 1:].contiguous()\n",
        "\n",
        "            logits, _ = model(inputs[:, :-1])\n",
        "\n",
        "            logits = logits.view(-1, logits.size(-1))\n",
        "            targets = targets.view(-1)\n",
        "\n",
        "            loss = criterion(logits, targets)\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(val_loader)"
      ],
      "metadata": {
        "id": "nP8oi22MYxZQ"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_gpt(model, train_data, val_data, config):\n",
        "    if torch.cuda.is_available():\n",
        "        device = torch.device(\"cuda\")\n",
        "    else:\n",
        "        device = torch.device(\"cpu\")\n",
        "\n",
        "    print(f\"Setting device to {device}\")\n",
        "\n",
        "    model.to(device)\n",
        "\n",
        "    train_dataset = TensorDataset(train_data)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=config.learning_rate)\n",
        "\n",
        "    for epoch in range(config.num_epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "\n",
        "        pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{config.num_epochs}\")\n",
        "\n",
        "        for batch in pbar:\n",
        "            inputs = batch[0].to(device)\n",
        "            targets = inputs[:, 1:].contiguous()\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Ajuste aqui: lidamos com a saída do modelo corretamente\n",
        "            logits, _ = model(inputs[:, :-1])\n",
        "\n",
        "            # Certifique-se de que logits e targets têm as formas corretas\n",
        "            logits = logits.view(-1, logits.size(-1))\n",
        "            targets = targets.view(-1)\n",
        "\n",
        "            loss = criterion(logits, targets)\n",
        "\n",
        "            loss.backward()\n",
        "\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            # Update the progress bar with the current loss\n",
        "            pbar.set_postfix({'batch_loss': loss.item()})\n",
        "\n",
        "        model.eval()\n",
        "        val_loss = evaluate(model, val_data, criterion, device)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{config.num_epochs}, \"\n",
        "              f\"Train Loss: {total_loss/len(train_loader):.4f}, \"\n",
        "              f\"Val Loss: {val_loss:.4f}\")\n",
        "\n",
        "def evaluate(model, val_data, criterion, device):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        val_dataset = TensorDataset(val_data)\n",
        "        val_loader = DataLoader(val_dataset, batch_size=64)\n",
        "\n",
        "        for batch in val_loader:\n",
        "            inputs = batch[0].to(device)\n",
        "            targets = inputs[:, 1:].contiguous()\n",
        "\n",
        "            # Ajuste aqui: lidamos com a saída do modelo corretamente\n",
        "            logits, _ = model(inputs[:, :-1])\n",
        "\n",
        "            # Certifique-se de que logits e targets têm as formas corretas\n",
        "            logits = logits.view(-1, logits.size(-1))\n",
        "            targets = targets.view(-1)\n",
        "\n",
        "            loss = criterion(logits, targets)\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(val_loader)\n"
      ],
      "metadata": {
        "id": "5nWkr23PvJa1"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_data(data, vocab_size, ctx_size):\n",
        "    # Flatten the list of token ids\n",
        "    flat_data = [token for example in data for token in example['input_ids']]\n",
        "\n",
        "    # Ensure all tokens are within the vocabulary range\n",
        "    flat_data = [token if token < vocab_size else vocab_size - 1 for token in flat_data]\n",
        "\n",
        "    # Create sequences of length ctx_size\n",
        "    sequences = [flat_data[i:i+ctx_size] for i in range(0, len(flat_data) - ctx_size + 1, ctx_size)]\n",
        "\n",
        "    # Pad the last sequence if necessary\n",
        "    if len(sequences[-1]) < ctx_size:\n",
        "        sequences[-1] = sequences[-1] + [0] * (ctx_size - len(sequences[-1]))\n",
        "\n",
        "    return torch.tensor(sequences)"
      ],
      "metadata": {
        "id": "BJE9xWjJepcZ"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Login to Hugging Face Hub\n",
        "notebook_login()"
      ],
      "metadata": {
        "id": "lETsHTAJaSGp",
        "outputId": "acfa5fa7-8342-419c-8d7a-b0ecd951f01b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331,
          "referenced_widgets": [
            "85c06097e02e4a0aad5db32d0eea1435",
            "62547b0b691e4a1da9853a295e7b553f",
            "e21b4a89313f42e289494836194ebdb0",
            "ed1c98a1ccb64470a2827d276eb8da13",
            "6edcd676bda145b29f28302c6e8fd7cb",
            "4228919ae31449a092087bd49d9d9439",
            "a101c7daec204c15bf8fe87f0cb1e83d",
            "03c9f2524475483fbbc08419e9c0d4ab",
            "7d033d83d8c64959a5900acf713b69a8",
            "d413339a5f414576919f07776776aa54",
            "c42b8d5c68ec4d6781b68a578f8c811e",
            "e759f253277a482eb0491334401611d4",
            "d60ce6621c214e8cad334f480f9071f0",
            "8b59145c938d43dc92e0f0c36a7ba9ac",
            "6c379091c4b94eb48d174ba303ea3b3c",
            "394435c48d3b4726affb6c5cd9520b02",
            "ab392532087143ad8b8cd920b7c071b4"
          ]
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "85c06097e02e4a0aad5db32d0eea1435"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Exemplo de uso\n",
        "config = GPTConfig(\n",
        "    n_vocab=50257,\n",
        "    n_pos=1024,\n",
        "    n_ctx=1024,\n",
        "    n_embed=768,\n",
        "    n_layer=12,\n",
        "    n_head=12,\n",
        "    layer_norm_epsilon=0.00001,\n",
        "\n",
        "    batch_size=12,\n",
        "    learning_rate=1e-4,\n",
        "    num_epochs=10\n",
        ")\n",
        "\n",
        "#model = GPT2(config)\n",
        "\n",
        "encoder = tiktoken.encoding_for_model(\"gpt-2\")\n",
        "\n",
        "def tokenize(examples):\n",
        "    return {\"input_ids\": encoder.encode(examples[\"text\"])}\n",
        "\n",
        "dataset = load_dataset(\"karpathy/tiny_shakespeare\")\n",
        "\n",
        "tokenized_datasets = dataset.map(tokenize, remove_columns=[\"text\"])\n",
        "\n",
        "# Prepare the dataset\n",
        "train_data = prepare_data(tokenized_datasets[\"train\"], config.n_vocab, config.n_ctx)\n",
        "val_data = prepare_data(tokenized_datasets[\"validation\"], config.n_vocab, config.n_ctx)\n",
        "\n",
        "print(f\"Train data shape: {train_data.shape}\")\n",
        "print(f\"Validation data shape: {val_data.shape}\")\n",
        "\n",
        "# Train the model\n",
        "train_gpt(model, train_data, val_data, config)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "89Dl7bG5Rife",
        "outputId": "8cceeb8d-3bc5-412f-d088-9070ac3bddae"
      },
      "execution_count": 35,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train data shape: torch.Size([294, 1024])\n",
            "Validation data shape: torch.Size([17, 1024])\n",
            "Setting device to cuda\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/10: 100%|██████████| 25/25 [00:21<00:00,  1.17it/s, batch_loss=3.75]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10, Train Loss: 5.2282, Val Loss: 7.1012\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2/10: 100%|██████████| 25/25 [00:21<00:00,  1.17it/s, batch_loss=3.2]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2/10, Train Loss: 3.2622, Val Loss: 7.3204\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3/10: 100%|██████████| 25/25 [00:21<00:00,  1.17it/s, batch_loss=2.83]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3/10, Train Loss: 2.8653, Val Loss: 7.7213\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4/10: 100%|██████████| 25/25 [00:21<00:00,  1.17it/s, batch_loss=2.66]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4/10, Train Loss: 2.7170, Val Loss: 7.9885\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5/10: 100%|██████████| 25/25 [00:21<00:00,  1.17it/s, batch_loss=2.85]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5/10, Train Loss: 2.6361, Val Loss: 8.2555\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/10: 100%|██████████| 25/25 [00:21<00:00,  1.17it/s, batch_loss=2.6]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/10, Train Loss: 2.5606, Val Loss: 8.7583\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/10: 100%|██████████| 25/25 [00:21<00:00,  1.17it/s, batch_loss=2.52]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/10, Train Loss: 2.4950, Val Loss: 8.7853\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/10: 100%|██████████| 25/25 [00:21<00:00,  1.17it/s, batch_loss=2.42]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/10, Train Loss: 2.4142, Val Loss: 8.8598\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/10: 100%|██████████| 25/25 [00:21<00:00,  1.17it/s, batch_loss=2.24]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/10, Train Loss: 2.3301, Val Loss: 9.0201\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/10: 100%|██████████| 25/25 [00:21<00:00,  1.17it/s, batch_loss=2.42]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/10, Train Loss: 2.3235, Val Loss: 9.0320\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import tiktoken\n",
        "\n",
        "def sample_from_model(model, prompt, max_length=100, temperature=1.0, top_k=None, device='cpu'):\n",
        "    model.eval()\n",
        "    model.to(device)\n",
        "\n",
        "    # Initialize the GPT-2 tokenizer\n",
        "    enc = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "    # Encode the prompt\n",
        "    input_ids = torch.tensor(enc.encode(prompt)).unsqueeze(0).to(device)\n",
        "\n",
        "    # Generate text\n",
        "    generated = input_ids\n",
        "    with torch.no_grad():\n",
        "        for _ in range(max_length):\n",
        "            # Get the model's output\n",
        "            outputs, _ = model(generated)\n",
        "            next_token_logits = outputs[:, -1, :] / temperature\n",
        "\n",
        "            # Apply top-k filtering if specified\n",
        "            if top_k is not None:\n",
        "                top_k_logits, top_k_indices = torch.topk(next_token_logits, top_k)\n",
        "                next_token_logits[next_token_logits < top_k_logits[:, [-1]]] = -float('Inf')\n",
        "\n",
        "            # Sample from the filtered distribution\n",
        "            probs = F.softmax(next_token_logits, dim=-1)\n",
        "            next_token = torch.multinomial(probs, num_samples=1)\n",
        "\n",
        "            # Append the new token to the sequence\n",
        "            generated = torch.cat((generated, next_token), dim=1)\n",
        "\n",
        "            # Stop if we generate an EOS token\n",
        "            if next_token.item() == enc.eot_token:\n",
        "                break\n",
        "\n",
        "    # Decode the generated text\n",
        "    generated_text = enc.decode(generated[0].tolist())\n",
        "\n",
        "    return generated_text"
      ],
      "metadata": {
        "id": "6woT9rQReMH3"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_from_model(model, \"Hello World\")"
      ],
      "metadata": {
        "id": "Nkz4KYaGi-z4",
        "outputId": "5940abab-470a-42b8-a951-60f4f1113788",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Hello World trib that l with musician Here Here Here Here are as patient; and forth\\n time:\\n\\nHere in beauty warm, will be, much:\\nCome, a IfElse will say you. Here Here: they send you, see your I am your Is this were;ANTIGON:\\nSpeak, my good warrant thee, and, on; and arrived and, sir.uncle, and only to thee, little, my brother, cens be, he took your royal dame'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VqE29PN1jEBf"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Como aproveitar ao máximo sua assinatura do Colab",
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "85c06097e02e4a0aad5db32d0eea1435": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_62547b0b691e4a1da9853a295e7b553f",
              "IPY_MODEL_e21b4a89313f42e289494836194ebdb0",
              "IPY_MODEL_ed1c98a1ccb64470a2827d276eb8da13",
              "IPY_MODEL_6edcd676bda145b29f28302c6e8fd7cb",
              "IPY_MODEL_4228919ae31449a092087bd49d9d9439"
            ],
            "layout": "IPY_MODEL_a101c7daec204c15bf8fe87f0cb1e83d"
          }
        },
        "62547b0b691e4a1da9853a295e7b553f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_03c9f2524475483fbbc08419e9c0d4ab",
            "placeholder": "​",
            "style": "IPY_MODEL_7d033d83d8c64959a5900acf713b69a8",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "e21b4a89313f42e289494836194ebdb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_d413339a5f414576919f07776776aa54",
            "placeholder": "​",
            "style": "IPY_MODEL_c42b8d5c68ec4d6781b68a578f8c811e",
            "value": ""
          }
        },
        "ed1c98a1ccb64470a2827d276eb8da13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_e759f253277a482eb0491334401611d4",
            "style": "IPY_MODEL_d60ce6621c214e8cad334f480f9071f0",
            "value": true
          }
        },
        "6edcd676bda145b29f28302c6e8fd7cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_8b59145c938d43dc92e0f0c36a7ba9ac",
            "style": "IPY_MODEL_6c379091c4b94eb48d174ba303ea3b3c",
            "tooltip": ""
          }
        },
        "4228919ae31449a092087bd49d9d9439": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_394435c48d3b4726affb6c5cd9520b02",
            "placeholder": "​",
            "style": "IPY_MODEL_ab392532087143ad8b8cd920b7c071b4",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "a101c7daec204c15bf8fe87f0cb1e83d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "03c9f2524475483fbbc08419e9c0d4ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d033d83d8c64959a5900acf713b69a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d413339a5f414576919f07776776aa54": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c42b8d5c68ec4d6781b68a578f8c811e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e759f253277a482eb0491334401611d4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d60ce6621c214e8cad334f480f9071f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8b59145c938d43dc92e0f0c36a7ba9ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c379091c4b94eb48d174ba303ea3b3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "394435c48d3b4726affb6c5cd9520b02": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab392532087143ad8b8cd920b7c071b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}